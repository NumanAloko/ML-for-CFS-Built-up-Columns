{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS/fvnXoohFMW3WKvrI4MB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NumanAloko/ML-for-CFS-Built-up-Columns/blob/main/RF_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and testing of Random Forest (RF) classification ML model**"
      ],
      "metadata": {
        "id": "hnYAa5Fo76ql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0Twjnhw2rIk"
      },
      "outputs": [],
      "source": [
        "# Import Python Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, learning_curve\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataframe\n",
        "csv_url= \"https://raw.githubusercontent.com/NumanAloko/ML-for-CFS-Built-up-Columns/refs/heads/main/CFS_Built-up_Columns_ML_Dataset.csv\"\n",
        "df = pd.read_csv(csv_url, header=0)\n",
        "df = df.dropna(how='all').dropna(axis=1, how='all')\n",
        "# Encode the 'Failure modes' column\n",
        "df['FM'] = df['FM'].str.strip()\n",
        "le = LabelEncoder()\n",
        "df['FM'] = le.fit_transform(df['FM'])\n",
        "\n",
        "data_x = df[['L', 't', 'h', 'b','Fy', '位c', '位(le-d)']]\n",
        "X = pd.DataFrame(df, columns=data_x.columns)\n",
        "\n",
        "# Scale the data\n",
        "sc_X = StandardScaler()\n",
        "X_scaled = sc_X.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets for the classification task\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_scaled, df['FM'], test_size=0.3, random_state=123)\n",
        "\n",
        "# Print the shapes of the resulting datasets to verify\n",
        "print(\"X_train_class shape:\", X_train_class.shape)\n",
        "print(\"X_test_class shape:\", X_test_class.shape)\n",
        "print(\"y_train_class shape:\", y_train_class.shape)\n",
        "print(\"y_test_class shape:\", y_test_class.shape)"
      ],
      "metadata": {
        "id": "LMwqRlvc6B9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning based on Grid search method\n",
        "# Define the parameter grid\n",
        "#param_grid = {\n",
        "    #'n_estimators': [100, 200, 300],\n",
        "    #'max_depth': [3, 4, 5, 6, None],\n",
        "    #'min_samples_split': [2, 5, 10],\n",
        "    #'min_samples_leaf': [1, 2, 4],\n",
        "    #'bootstrap': [True, False]\n",
        "#}\n",
        "\n",
        "# Optimised Hyperparameters (Best parameters selected after tuning)\n",
        "param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [None],\n",
        "    'min_samples_split': [5],\n",
        "    'min_samples_leaf': [1],\n",
        "    'bootstrap': [False]\n",
        "}\n",
        "\n",
        "# Define the Random forest (RF)  classification model\n",
        "rf = RandomForestClassifier(random_state=123)\n",
        "clf = GridSearchCV(estimator=rf, cv=10, param_grid=param_grid, n_jobs=-1)\n",
        "\n",
        "# Train the classifier on feature and target data\n",
        "clf.fit(X_train_class, y_train_class)\n",
        "\n",
        "# View the accuracy score\n",
        "print('Best score for data:', clf.best_score_)\n",
        "\n",
        "# View the best parameters for the model found using grid search\n",
        "print('Best n_estimators:', clf.best_estimator_.n_estimators)\n",
        "print('Best max_depth:', clf.best_estimator_.max_depth)\n",
        "print('Best min_samples_split:', clf.best_estimator_.min_samples_split)\n",
        "print('Best min_samples_leaf:', clf.best_estimator_.min_samples_leaf)\n",
        "print('Best bootstrap:', clf.best_estimator_.bootstrap)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_class_train = clf.predict(X_train_class)\n",
        "y_pred_class_test = clf.predict(X_test_class)"
      ],
      "metadata": {
        "id": "CPzfLptH6KWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################ Performance Metrics ##########################\n",
        "# Calculate accuracy\n",
        "accuracy_train = accuracy_score(y_train_class, y_pred_class_train)\n",
        "accuracy_test = accuracy_score(y_test_class, y_pred_class_test)\n",
        "\n",
        "print('Training accuracy: {:.2f}'.format(accuracy_train))\n",
        "print('Test accuracy: {:.2f}'.format(accuracy_test))\n",
        "\n",
        "# Print confusion matrix\n",
        "print('Confusion matrix:')\n",
        "print(confusion_matrix(y_test_class, y_pred_class_test))\n",
        "\n",
        "# Print classification report\n",
        "print('Classification report:')\n",
        "print(classification_report(y_test_class, y_pred_class_test))\n",
        "\n",
        "#  class names (Inverse Encoding)\n",
        "class_names = le.inverse_transform(np.unique(y_test_class))\n",
        "\n",
        "# Print the class names\n",
        "print('Classes:', class_names)\n",
        "# Get the mapping of class names to numbers\n",
        "class_mapping = {label: index for index, label in enumerate(le.classes_)}\n",
        "# Print the mapping\n",
        "print('Encoding:', class_mapping)"
      ],
      "metadata": {
        "id": "Bm3L2fCw62GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classify the failure mode of a new instance after training of RF ML Model**"
      ],
      "metadata": {
        "id": "ucXrMGh27I30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make new prediction\n",
        "# Manually input the new data\n",
        "\n",
        "new_data = {\n",
        "    'L': [1500],               # Length(mm)\n",
        "    't': [1.5],                # Thickness of the section (mm)\n",
        "    'h': [175],                # Height of the section (mm)\n",
        "    'b': [65],                 # Flange of the section (mm)\n",
        "    'Fy': [450],               # Yield stress\n",
        "    '位c': [0.38],              # Global Slenderness\n",
        "    '位(le-d)': [2.36],         # Sectional Slenderness\n",
        "}\n",
        "\n",
        "new_input_data = pd.DataFrame(new_data)\n",
        "\n",
        "# Ensure the new input data has the same columns as the training data\n",
        "new_input_data = new_input_data[data_x.columns]\n",
        "\n",
        "# Scale the new input data using the same scaler used for training data\n",
        "sc_X = StandardScaler()\n",
        "sc_X.fit(X)  # Fit the scaler on the original training data\n",
        "new_input_scaled = sc_X.transform(new_input_data)\n",
        "\n",
        "# Make predictions\n",
        "predicted_class = clf.predict(new_input_scaled)\n",
        "predicted_class_decoded = le.inverse_transform(predicted_class)\n",
        "\n",
        "print('Predicted class:', predicted_class_decoded[0])"
      ],
      "metadata": {
        "id": "rDHluOvP7aEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation of the new instance**"
      ],
      "metadata": {
        "id": "2D9OHmRZ7udt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RF Classification Model Explainer\n",
        "!pip install lime\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "# Create a LIME explainer\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train_class,\n",
        "    feature_names=X.columns,\n",
        "    class_names=class_names,\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# New input data\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=new_input_scaled[0],\n",
        "    predict_fn=clf.predict_proba, top_labels=1\n",
        ")\n",
        "\n",
        "# Show the explanation\n",
        "exp.show_in_notebook(show_table=True, show_all=False)"
      ],
      "metadata": {
        "id": "PB8yp0s27olM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
